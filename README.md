## MultiFrame-LPR

Multi-frame OCR solution for the **ICPR 2026 Challenge on Low-Resolution License Plate Recognition**.

This repository implements a **5-frame license plate recognizer** with:
- Modern **SVTRv2-based backbone** (`MultiFrameSVTRv2`)
- Optional **Spatial Transformer Network (STN)**
- Optional **Super-Resolution (MFâ€‘LPR / LPâ€‘Diff)** pre-processing

ğŸ”— **Challenge:** `https://icpr26lrlpr.github.io/`

---

## Quick Start

### 1. Environment

```bash
# Activate venv (PowerShell)
.\.venv\Scripts\Activate.ps1

# Install dependencies (uv)
uv sync
```

### 2. Train baseline OCR (khÃ´ng SR, dÃ¹ng MultiFrameSVTRv2 + STN)

```bash
python train.py \
  --model mf_svtrv2 \
  --experiment-name mfsvtrv2_baseline
```

> Máº·c Ä‘á»‹nh `MODEL_TYPE = "mf_svtrv2"` trong `configs/config.py`, nÃªn cÃ³ thá»ƒ chá»‰ cáº§n:
> ```bash
> python train.py
> ```

### 3. Báº­t Super-Resolution (MFâ€‘LPR / LPâ€‘Diff)

Giáº£ sá»­ báº¡n Ä‘Ã£ cÃ³ checkpoint SR:

```python
# configs/config.py
USE_SR: bool = True
SR_CHECKPOINT_PATH: str = r"weights/sr/mf_lpr_sr_best.pth"
SR_CONFIG_PATH: str = "sr_model/config/LP-Diff.json"
```

Cháº¡y:

```bash
python train.py --batch-size 32
```

Hoáº·c override tá»« CLI:

```bash
python train.py \
  --use-sr \
  --sr-checkpoint-path "weights/sr/mf_lpr_sr_best.pth"
```

### 4. Táº¡o submission cho test set

```bash
python train.py \
  --submission-mode \
  --experiment-name mfsvtrv2_submit
```

Káº¿t quáº£: `results/submission_mfsvtrv2_submit_final.txt`

---

## Key Features

- **Multi-Frame Fusion (5 frames)**: Input shape `(B, 5, 3, 32, 128)` vá»›i attention fusion.
- **MultiFrameSVTRv2 (máº·c Ä‘á»‹nh)**:
  - Backbone SVTRv2-LNConvTwo33
  - Attention fusion cho 5 frame
  - CTC head cho sequence decoding.
- **STN (tÃ¹y chá»n)**: CÄƒn chá»‰nh biá»ƒn sá»‘ trÆ°á»›c khi Ä‘Æ°a vÃ o backbone.
- **Super-Resolution (MFâ€‘LPR / LPâ€‘Diff, tÃ¹y chá»n)**:
  - Pretrained diffusion SR model, cháº¡y **trÆ°á»›c** OCR.
  - TÃ­ch há»£p qua adapter `src/sr/mf_lpr_sr.py`.
- **Scenario-aware splitting**:
  - Split train/val Æ°u tiÃªn track tá»« Scenario-B, lÆ°u vÃ o `data/val_tracks.json`.
- **Training utilities**:
  - Mixed precision (`torch.amp`), gradient clipping, OneCycleLR, focal CTC loss (tÃ¹y chá»n).

---

## Model Architectures

### 1. MultiFrameSVTRv2 (máº·c Ä‘á»‹nh, tá»‘t nháº¥t)

**Pipeline:**  
`5Ã— LR Frames â†’ (optional STN) â†’ SVTRv2 Backbone â†’ Attention Fusion â†’ CTC Head`

- Äá»‹nh nghÄ©a trong `src/mf_svtrv2.py`
- Sá»­ dá»¥ng cáº¥u hÃ¬nh tá»« `configs/config.py` (`SVTR_DIMS`, `SVTR_DEPTHS`, `SVTR_HEADS`).
- Pretrained weights (vÃ­ dá»¥ UniRec) load tá»« `Config.PRETRAINED_PATH`.

### 2. ResTranOCR

**Pipeline:**  
`5Ã— Frames â†’ (optional STN) â†’ ResNet34 â†’ Attention Fusion â†’ Transformer Encoder â†’ CTC`

- Äá»‹nh nghÄ©a trong `src/models/restran.py`.
- Chá»n báº±ng `--model restran`.

### 3. MultiFrameCRNN

**Pipeline:**  
`5Ã— Frames â†’ (optional STN) â†’ CNN â†’ Attention Fusion â†’ BiLSTM â†’ CTC`

- Äá»‹nh nghÄ©a trong `src/models/crnn.py`.
- Chá»n báº±ng `--model crnn`.

---

## Installation

**YÃªu cáº§u:**
- Python 3.11+
- GPU há»— trá»£ CUDA (khuyáº¿n nghá»‹)

### Báº±ng uv (khuyáº¿n nghá»‹)

```bash
git clone <repo_url>
cd MultiFrame-LPR
uv sync
```

### Báº±ng pip (náº¿u khÃ´ng dÃ¹ng uv)

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install albumentations opencv-python matplotlib numpy pandas tqdm
```

---

## Data Preparation

Cáº¥u trÃºc thÆ° má»¥c:

```text
data/train/
â”œâ”€â”€ Scenario-A/
â”‚   â””â”€â”€ Brazilian/
â”‚       â”œâ”€â”€ track_00001/
â”‚       â”‚   â”œâ”€â”€ lr-0.png
â”‚       â”‚   â”œâ”€â”€ lr-1.png
â”‚       â”‚   â”œâ”€â”€ ...
â”‚       â”‚   â”œâ”€â”€ hr-0.png (tÃ¹y chá»n, dÃ¹ng cho synthetic LR)
â”‚       â”‚   â””â”€â”€ annotations.json
â”‚       â””â”€â”€ track_00002/
â”‚           â””â”€â”€ ...
â””â”€â”€ Scenario-B/
    â””â”€â”€ ...
```

`annotations.json` (tá»‘i thiá»ƒu):

```json
{"plate_text": "ABC1234"}
```

- Train/val split Ä‘Æ°á»£c táº¡o vÃ  lÆ°u vÃ o `data/val_tracks.json` (Scenario-B aware).
- Test public (náº¿u cÃ³) Ä‘áº·t trong `data/public_test/` cÃ¹ng cáº¥u trÃºc track nhÆ°ng **khÃ´ng cÃ³ annotations**.

---

## Training Usage

### Basic training (MultiFrameSVTRv2 + STN, khÃ´ng SR)

```bash
python train.py \
  --model mf_svtrv2 \
  --experiment-name mfsvtrv2_baseline
```

### Training vá»›i cáº¥u hÃ¬nh tuá»³ chá»‰nh

```bash
python train.py \
  --model mf_svtrv2 \
  --experiment-name my_exp \
  --data-root data/train \
  --batch-size 64 \
  --epochs 30 \
  --lr 3.25e-4 \
  --aug-level full
```

### Táº¯t STN

```bash
python train.py --no-stn
```

### Báº­t Super-Resolution (náº¿u Ä‘Ã£ cÃ³ checkpoint SR)

```bash
python train.py \
  --use-sr \
  --sr-checkpoint-path "weights/sr/mf_lpr_sr_best.pth"
```

### CÃ¡c tham sá»‘ CLI quan trá»ng

- `-m, --model`: `crnn`, `restran`, `mf_svtrv2` (default: `mf_svtrv2`)
- `-n, --experiment-name`: tÃªn thÃ­ nghiá»‡m, dÃ¹ng Ä‘á»ƒ Ä‘áº·t tÃªn file output
- `--data-root`: thÆ° má»¥c train (default: `data/train`)
- `--batch-size`: batch size (default: `64`)
- `--epochs`: sá»‘ epoch (default: tá»« `Config.EPOCHS`)
- `--lr, --learning-rate`: learning rate (default: `Config.LEARNING_RATE`)
- `--aug-level`: `full` hoáº·c `light`
- `--no-stn`: táº¯t STN
- `--submission-mode`: train trÃªn full data vÃ  táº¡o submission cho test
- `--output-dir`: thÆ° má»¥c lÆ°u káº¿t quáº£ (default: `results/`)
- `--use-sr`: báº­t Super-Resolution MFâ€‘LPR
- `--sr-checkpoint-path`: Ä‘Æ°á»ng dáº«n checkpoint GEN cá»§a SR
- `--sr-config-path`: Ä‘Æ°á»ng dáº«n JSON config SR (default: `sr_model/config/LP-Diff.json`)

---

## Super-Resolution Integration (MFâ€‘LPR / LPâ€‘Diff)

### Adapter: `src/sr/mf_lpr_sr.py`

```python
from src.sr import MF_LPR_SR

sr = MF_LPR_SR(
    checkpoint_path="weights/sr/mf_lpr_sr_best.pth",
    config_path="sr_model/config/LP-Diff.json",
    device=config.DEVICE,
)

sr_frames = sr.enhance_sequence(frames, resize_to=(32, 128))
```

- Adapter wrap láº¡i code gá»‘c trong `sr_model/` (UNet + GaussianDiffusion + MTA).
- Chá»‰ dÃ¹ng cho **inference**; SR model Ä‘Æ°á»£c pretrained vÃ  Ä‘Ã³ng bÄƒng, **khÃ´ng train cÃ¹ng OCR**.

### Báº­t/táº¯t SR trong pipeline

Trong `configs/config.py`:

```python
USE_SR: bool = True  # hoáº·c False
SR_CHECKPOINT_PATH: str = r"weights/sr/mf_lpr_sr_best.pth"
SR_CONFIG_PATH: str = "sr_model/config/LP-Diff.json"
```

Trong `train.py`, náº¿u `USE_SR=True` vÃ  `SR_CHECKPOINT_PATH` há»£p lá»‡:
- Khá»Ÿi táº¡o `MF_LPR_SR`.
- Truyá»n `sr_enhancer` vÃ o `MultiFrameDataset`.
- Má»—i sample (5 frame) Ä‘Æ°á»£c SR trÆ°á»›c khi vÃ o model OCR.

âš ï¸ **LÆ°u Ã½ runtime:**  
Diffusion SR ráº¥t náº·ng (1000 bÆ°á»›c / láº§n). Äá»ƒ train thá»±c táº¿:
- NÃªn giáº£m `n_timestep` trong config SR (vÃ­ dá»¥ 50â€“100).
- Hoáº·c chá»‰ SR frame giá»¯a.
- Hoáº·c precompute áº£nh SR offline rá»“i train OCR trÃªn áº£nh SR Ä‘Ã£ lÆ°u.

---

## Outputs

Táº¥t cáº£ file output Ä‘á»u Ä‘Æ°á»£c lÆ°u trong `OUTPUT_DIR` (default: `results/`).

### Checkpoints

- **`{EXPERIMENT_NAME}_best.pth`**
  - Model tá»‘t nháº¥t theo **Val Accuracy** (luÃ´n cÃ³).
- **`{EXPERIMENT_NAME}_final.pth`**
  - Trá»ng sá»‘ model **epoch cuá»‘i** (chá»‰ khi cÃ³ validation; khÃ´ng cÃ³ trong `--submission-mode`).

### Submission files

- **`submission_{EXPERIMENT_NAME}.txt`**
  - Dá»± Ä‘oÃ¡n trÃªn **validation set** má»—i khi cÃ³ best má»›i.
  - Format: `track_id,pred_text;confidence`.
- **`submission_{EXPERIMENT_NAME}_final.txt`**
  - Chá»‰ khi `--submission-mode` vÃ  cÃ³ test data.
  - Dá»± Ä‘oÃ¡n cho **test set** Ä‘á»ƒ ná»™p bÃ i.

### Wrong predictions

- **`wrong_predictions_{EXPERIMENT_NAME}.txt`**
  - Sinh ra khi:
    - CÃ³ validation
    - `SAVE_WRONG_PREDICTIONS=True` (default)
    - CÃ³ Ã­t nháº¥t 1 sample sai
  - Format:
    ```text
    track_id    ground_truth    prediction    confidence    img_paths
    track_00042 ABC1234         ABC1235      0.8234        data/.../track_00042/lr-0.png;...;lr-4.png
    ```
  - `img_paths` giÃºp báº¡n má»Ÿ nhanh Ä‘Ãºng 5 áº£nh cá»§a sample bá»‹ sai.

---

## Configuration (tÃ³m táº¯t)

CÃ¡c hyperparameter chÃ­nh trong `configs/config.py`:

```python
MODEL_TYPE: str = "mf_svtrv2"   # "crnn", "restran", "mf_svtrv2"
EXPERIMENT_NAME: str = MODEL_TYPE
AUGMENTATION_LEVEL: str = "full"   # "full" hoáº·c "light"
USE_STN: bool = True

DATA_ROOT: str = "data/train"
TEST_DATA_ROOT: str = "data/public_test"

BATCH_SIZE: int = 64
LEARNING_RATE: float = 3.25e-4
EPOCHS: int = 1      # chá»‰nh trong config hoáº·c override báº±ng CLI

USE_FOCAL_CTC: bool = True
CTC_BEAM_WIDTH: int = 1

PRETRAINED_PATH: str = r"weights/best.pth"   # cho mf_svtrv2 / restran / crnn

USE_SR: bool = False                         # báº­t/táº¯t SR
SR_CHECKPOINT_PATH: str = ""                 # cáº§n set náº¿u USE_SR=True
SR_CONFIG_PATH: str = "sr_model/config/LP-Diff.json"
```

Táº¥t cáº£ cÃ¡c field cÃ³ thá»ƒ override qua CLI (`arg_to_config` trong `train.py`).

---

## Project Structure

```text
.
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.py                 # Dataclass cáº¥u hÃ¬nh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py            # MultiFrameDataset (5 frames, scenario-aware split, optional SR)
â”‚   â”‚   â””â”€â”€ transforms.py         # Augmentation pipelines
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ crnn.py               # Multi-frame CRNN
â”‚   â”‚   â”œâ”€â”€ restran.py            # ResTranOCR
â”‚   â”‚   â””â”€â”€ components.py         # STN, AttentionFusion, etc.
â”‚   â”œâ”€â”€ sr/
â”‚   â”‚   â”œâ”€â”€ mf_lpr_sr.py          # MF-LPR / LP-Diff adapter (SR)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py            # Training, validation, saving outputs
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ common.py             # seed, CUDA utils, memory estimate
â”‚       â””â”€â”€ postprocess.py        # CTC decoding, CER
â”œâ”€â”€ sr_model/                     # Original LP-Diff SR implementation
â”‚   â”œâ”€â”€ config/LP-Diff.json       # SR config
â”‚   â”œâ”€â”€ model/                    # UNet + GaussianDiffusion + MTA
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train.py                      # Main training / submission script
â”œâ”€â”€ run_ablation.py               # Ablation study (khÃ´ng báº¯t buá»™c)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ add_sr.md                 # HÆ°á»›ng dáº«n tÃ­ch há»£p SR (chi tiáº¿t)
â”‚   â”œâ”€â”€ CHECKPOINT_PATHS.md       # HÆ°á»›ng dáº«n Ä‘áº·t checkpoint
â”‚   â”œâ”€â”€ HOW_TO_VERIFY_SR.md       # CÃ¡ch kiá»ƒm tra SR Ä‘Ã£ tÃ­ch há»£p
â”‚   â””â”€â”€ OUTPUTS_AFTER_RUN.md      # Giáº£i thÃ­ch file output
â””â”€â”€ pyproject.toml                # Dependencies
```

---

## Notes & Recommendations

- **Khi debug / thá»­ nghiá»‡m nhanh**, nÃªn:
  - Äáº·t `USE_SR=False` Ä‘á»ƒ training nhanh.
  - DÃ¹ng subset data + `EPOCHS=1` Ä‘á»ƒ kiá»ƒm tra pipeline.
- **Khi báº­t SR Ä‘á»ƒ train nghiá»‡m chá»‰nh**, hÃ£y:
  - Äáº£m báº£o checkpoint SR cháº¡y á»•n vá»›i `test_sr_integration.py`.
  - CÃ¢n nháº¯c giáº£m `n_timestep` hoáº·c chá»‰ SR frame trung tÃ¢m Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian.
